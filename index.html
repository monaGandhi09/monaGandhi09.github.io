<!DOCTYPE html>
<html lang='en'>

<head>
	<meta charset='UTF-8'>
	<meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'>
	<title>Mona Gandhi</title>
	<meta http-equiv='X-UA-Compatible' content='IE=edge'>
	<link rel='stylesheet' href='asset/css/bootstrap.css'>
	<link rel='stylesheet' href='asset/css/all.css'>
	<link rel='stylesheet' href='asset/css/style.css'>
</head>

<body class='bg-light'>
	<header>
		<nav class='navbar navbar-light fixed-top bg-light'>
			<a class='navbar-brand col-sm-3 col-md-2 mt-1 ml-5' href='index.html'>
				<h2>MONA GANDHI</h2>
			</a>
			<ul class="nav justify-content-center">
				<li class="nav-item">
					<a class=" nav-link" href="asset/pdf/Resume.pdf">Resume</a>
				</li>
				<li class="nav-item">
					<a class=" nav-link" href="#research">Research</a>
				</li>
				<li class="nav-item">
					<a class=" nav-link" href="#project">Projects</a>
				</li>
			</ul>
		</nav>
	</header>
	<section id="top">
		<div class='container pt-5'>
			<div class="row pt-5">
				<div class="col-3">
					<img class="img-fluid rounded" src="asset/image/mona.jpg" alt="headshot">
				</div>
				<div class="col-9">
					<h4 class=''>M.S in Computer Science @ University of Pennsylvania</h4>
					<div class="row">
						<p class="text-muted mx-3 my-2">mona09 [at] seas.upenn.edu</p>
						<span class="icon"><a class="text-dark" href="https://www.linkedin.com/in/monagandhi09/"><i
							class="fab fa-linkedin mx-2"></i></a></span>
						<span class="icon"><a class="text-dark"
								href="https://scholar.google.com/citations?user=1wHg0-sAAAAJ&hl=en"><i
									class="fas fa-graduation-cap mx-2"></i></a></span>
						<span class="icon"><a class="text-dark" href="https://github.com/monaGandhi09/"><i
									class="fab fa-github mx-2"></i></a></span>
						<span class="icon"><a class="text-dark"
							href="https://twitter.com/monagandhi09"><i class="fab fa-1x fa-twitter mx-2"></i></a></span>
					</div>
					<p>I am a Masters student majoring in Computer Science at Unoversity of Pennsylvania, where 
						I have been doing research with the wonderful <a href="https://www.cis.upenn.edu/~myatskar/">Prof. Mark Yatskar</a>.
						Along with which I have also been lucky to be working with
						<a class="" href="https://ranjaykrishna.com/index.html">Prof. Ranjay Krishna</a> at University of Washington 
						and his cohort on various research projects.
					</p>
				</div>
			</div>
			<div class="row pt-5">
				My current research interests lie at the intersection of vision and language, which have been the focus of my past research
				experiences. I am specifically keen on studying interpretability of large models which is the focus of my recent research with Prof. Mark Yatskar
				and also with Prof. Ranjay Krishna.
			</div>
			<!-- <div class="row pt-5">
					<p> My past projects cover multi-agent coordination, large language and vision models, and human-computer interaction.
						My current research interests lie in the intersection between AI/ML and HCI, especially human-AI interaction and collaboration. I'm broadly interested in these research questions:<br>
						<ul>
							<li class="bg-light">Human side: what do end users need when collaborating with AI? How can we make explanations helpful (if possible) in human-AI collaboration?</li>
							<li class="bg-light">AI/ML side: how do we develop ML models that can adapt to diverse user needs and behaviors?</li>
							<li class="bg-light">Interaction: what human-AI interactions are possible? How can we leverage interaction data to inform model design and development?</li>
						</ul>
					</p>
			</div> -->
		</div>
	</section>
	<section class="mx-5 my-5" id="highlights">
		<h3 class="mx-5">Highlights and Achievements</h3>
		<ul class=" mx-5">
			<li class="bg-light">
				<b>[Mar, 2023] </b> Our paper <i>CREPE: Can Vision-Language Foundation Models Reason Compositionally?</i> has been accepted to CVPR 2023 and selected as a &#127775;<b>highlight</b>&#127775;!
			</li>
			<li class="bg-light">
				<b>[Mar, 2022] </b> Our paper <i>Measuring Compositional Consistency for Video Question Answering</i> has been accepted to CVPR 2022.
			</li>
			<li class="bg-light">
				<b>[June, 2018] </b> Stood <b><i>1st</i></b> among girls in MHT-CET (state-level entrance exam) which is appeared by 0.28M candidates.
			</li>
		</ul>
		</div>
	</section>
	<section class="mx-5 my-5" id="research">
		<h3 class="mx-5">Selected publications</h3>
		<ul class="list-group list-group-flush mx-5">
			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-3"><img class="img-fluid" src="asset/image/crepe.png" alt="crepe image">
					</div>
					<div class="col-9">
						<h4 id='top' class=''>CREPE: Can Vision-Language Foundation Models Reason Compositionally?</h4>
						<p>Zixian Ma*, Jerry Hong*, Mustafa Omer Gul*, <b><u>Mona Gandhi</u></b>, Irena Gao, Ranjay Krishna</p>
						<p>CVPR 2023 <span style="color:red;">
							[Highlight: 10% of accepted papers / 2.5% of submissions]</span></p>
						<p><a href="https://arxiv.org/pdf/2212.07796.pdf">[PDF]</a></p>
					</div>
			</li>
			<li class="list-group-item bg-light">
				<div class="row">
					<div class="col-3"><img class="img-fluid" src="asset/image/AGQA-Decomp.png" alt="AGQA Decomp image" style="height: 170px; width: 290px;">
					</div>
					<div class="col-9">
						<h4 id='top' class=''>Measuring Compositional Consistency for Video Question Answering</h4>
						<p><b><u>Mona Gandhi</u>*</b>, Mustafa Omer Gul*, Eva Prakash, Madeleine Grunde-McLaughlin, Ranjay Krishna, Maneesh Agrawala</p>
						<p>CVPR 2022</p>
						<p>
							<a href="https://arxiv.org/pdf/2204.07190.pdf">[PDF]</a> 
							<a href="https://agqa-decomp.cs.washington.edu/">[Website]</a> 
							<a href="https://github.com/madeleinegrunde/AGQA_baselines_code">[Code]</a>
							<a href="https://agqa-decomp.cs.washington.edu/#data">[Data]</a>
						</p>
					</div>
			</li>
			
		</ul>
		</div>
	</section>
	<section class="mx-5 my-5" id="project">
		<h3 class="mx-5">Projects</h3>
		<div class="row mx-5">
			<div class="col-4">
				<div class="card mt-3 h-100">
					<div class="card-body pb-0">
						<h5 class="card-title">Could this be any better?</h5>
						<h6 class="card-subtitle mb-2 text-muted">Multi-modal Sarcasm Detector [Fall 2022]</h6>
						<p class="card-text"><i>Domain: </i>Computer Vision and Natural Language Processing</p>
						<p class="card-text">
							We implemented a Multi-modal Sarcasm Detector using video, audio and text features from the MUStARD dataset - data from 
							various TV sitcoms like Friends, Big Bang Theory. 
							Training and analyzing the performance of LSTMs with different types of attention mechanisms, we found 
							the best performing model to learn a bias towards labeling data as sarcastic, but does very well in detecting non-sarcastic data.
						</p>
						<a href="asset/pdf/SarcasmDetector.pdf"
							class="card-link">[Report]</a>
						<a href="asset/pdf/SarcasmDetectorPresentation.pdf"
							class="card-link">[Presentation]</a>
							<a href="asset/image/SarcasmDetector.mp4"
							class="card-link">[Video]</a>
						<!-- <a href=""
							class="card-link">[GitHub]</a> -->
					</div>
				</div>
			</div>
			<div class="col-4">
				<div class="card mt-3 h-100">
					<div class="card-body pb-0">
						<h5 class="card-title">&#9888; Alert!! False News! &#9888;</h5>
						<h6 class="card-subtitle mb-2 text-muted">Fake News Detector [Spring 2021]</h6>
						<p class="card-text"><i>Domain: </i>Natural Language Processing</p>
						<p class="card-text">
							We developed a Fake-News Detector using Transformer-based model - BERT trained on LIAR dataset. On analysis,
							we infer that  the model does well classifying false statements, and does a poor job classifying true statements.
						</p>
						<a href="asset/pdf/FakeNews.pdf"
							class="card-link">[Report]</a>
						<a href="https://github.com/monaGandhi09/ML-Project"
							class="card-link">[GitHub]</a>
					</div>
				</div>
			</div>
			<div class="col-4">
				<div class="card mt-3 h-100">
					<div class="card-body pb-0">
						<h5 class="card-title">AlgoVisualizer</h5>
						<h6 class="card-subtitle mb-2 text-muted">Visualizer for Algorithms [Spring 2020]</h6>
						<p class="card-text"><i>Technologies: </i>HTML, CSS, ReactJS</p>
						<p class="card-text">
							Many algorithms in computer science become easier to understand if visualized.
							I developed a tool to visualize sorting algorithms like bubble sort, merge sort and insertion sort 
							where every comparison the algorithm makes can be seen. There is an interactive page to see every node 
							path finding algorithms like BFS, DFS, Dijkstra's visit where one can add weights and walls in the grid. 
							Making comparing various algorithms against each other easier. 
						</p>
						<a href="asset/pdf/AlgoVisualizer.pdf"
							class="card-link">[Report]</a>
						<a href="https://github.com/monaGandhi09/AlgoVisualizer"
							class="card-link">[GitHub]</a>
					</div>
				</div>
			</div>
		</div>

	</section>

	<hr class='featurette-divider'>
	<footer>
		<p class='mx-5 d-flex justify-content-end'><a class="" href='#top'>Back to top</a></p>
	</footer>
</body>

</html>